{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1710571975374,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"-cPdAo973Wgu","outputId":"5642fc81-e311-49f3-eb68-f939b22d0e5b"},"outputs":[{"data":{"text/plain":["'\\nPatrick Ballou\\nID: 801130521\\nECGR 4106\\nHomework 3\\nProblem 2\\n'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Patrick Ballou\n","ID: 801130521\n","ECGR 4106\n","Homework 3\n","Problem 2\n","'''"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6866,"status":"ok","timestamp":1710571982741,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"H1wFROy23Wgz"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import time\n","import requests\n","from torch import cuda\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import pandas as pd\n","from sklearn import metrics\n","from sklearn.preprocessing import StandardScaler as SS\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1710571983055,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"7cit46jG3Wg1","outputId":"7a1d7df2-9c7f-4d93-8415-5cffdf7aca87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using GPU:  Quadro T2000\n","Sun Mar 17 19:44:57 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 551.23                 Driver Version: 551.23         CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Quadro T2000                 WDDM  |   00000000:01:00.0  On |                  N/A |\n","| N/A   55C    P8              5W /   30W |     575MiB /   4096MiB |     16%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|    0   N/A  N/A      1788    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n","|    0   N/A  N/A      5084    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n","|    0   N/A  N/A      7208    C+G   ...41.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n","|    0   N/A  N/A     10352    C+G   ...e Stream\\88.0.0.0\\GoogleDriveFS.exe      N/A      |\n","|    0   N/A  N/A     12968    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n","|    0   N/A  N/A     14388    C+G   C:\\Windows\\explorer.exe                     N/A      |\n","|    0   N/A  N/A     14988    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n","|    0   N/A  N/A     15592    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n","|    0   N/A  N/A     15932    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n","|    0   N/A  N/A     17808    C+G   ....1300.0_x64__8j3eq9eme6ctt\\IGCC.exe      N/A      |\n","|    0   N/A  N/A     18876    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n","|    0   N/A  N/A     19076    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n","|    0   N/A  N/A     19888    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n","|    0   N/A  N/A     20148    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n","|    0   N/A  N/A     21240    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n","|    0   N/A  N/A     21896    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["#check if GPU is available and set the device accordingly\n","#device = 'torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")'\n","device = 'cuda'\n","print(\"Using GPU: \", cuda.get_device_name())\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":590,"status":"ok","timestamp":1710571983641,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"9qS2mSws3Wg1"},"outputs":[],"source":["# Pred dataset for training\n","url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","response = requests.get(url)\n","text = response.text  # This is the entire text data\n","\n","chars = sorted(list(set(text)))\n","char_to_int = {ch: i for i, ch in enumerate(chars)}\n","int_to_char = {i: ch for i, ch in enumerate(chars)}\n","\n","# Encode the text into integers\n","encoded_text = [char_to_int[ch] for ch in text]"]},{"cell_type":"markdown","metadata":{"id":"98I324y83Wg2"},"source":["# **Problem 2A:** LSTM(20, 30, 50)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3564,"status":"ok","timestamp":1710571987204,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"MvgMivy03Wg3"},"outputs":[],"source":["sequence_length = 20\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604916,"status":"ok","timestamp":1710572592352,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"6AAFI0aE3Wg4","outputId":"4f9510b7-0c21-409c-ace1-45d15dd13545"},"outputs":[{"name":"stdout","output_type":"stream","text":["20 sequence LSTM results:\n","Epoch 1, Training Loss: 1.7039286458348653\n","Epoch 2, Training Loss: 1.4828566941152137\n","Epoch 3, Training Loss: 1.4228907150060912\n","Epoch 4, Training Loss: 1.3878118183188102\n","Epoch 5, Training Loss: 1.361920929226941\n","Epoch 6, Training Loss: 1.3428072792254024\n","Epoch 7, Training Loss: 1.3274340351217448\n","Epoch 8, Training Loss: 1.3143731060636092\n","Epoch 9, Training Loss: 1.303149068528253\n","Epoch 10, Training Loss: 1.2939258513953997\n","Epoch 11, Training Loss: 1.2853256974986964\n","Epoch 12, Training Loss: 1.2785495665657471\n","Epoch 13, Training Loss: 1.2721631698955835\n","Epoch 14, Training Loss: 1.2667568558447675\n","Epoch 15, Training Loss: 1.2605822635873323\n","Epoch 16, Training Loss: 1.2563257013852065\n","Epoch 17, Training Loss: 1.2524168876417054\n","Epoch 18, Training Loss: 1.2479410454827482\n","Epoch 19, Training Loss: 1.2448831394066842\n","Epoch 20, Training Loss: 1.2421532968594573\n","Epoch 21, Training Loss: 1.2385113516280655\n","Epoch 22, Training Loss: 1.2367871534068626\n","Epoch 23, Training Loss: 1.2343798212224015\n","Epoch 24, Training Loss: 1.232003951672843\n","Epoch 25, Training Loss: 1.2305857209350894\n","Training time: 10.025756839911143 minutes\n","Accuracy of test set: 58.42608988008517%\n"]}],"source":["# Defining the LSTM model\n","class CharLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.lstm(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n","                torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharLSTM(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"20 sequence LSTM results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2a_20.pth')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4748,"status":"ok","timestamp":1710572597078,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"tvqj2rgv3Wg5"},"outputs":[],"source":["sequence_length = 30\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678992,"status":"ok","timestamp":1710573276063,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"7mDq71Ys3Wg6","outputId":"67b06969-f7e7-4c93-dfa4-23b563172660"},"outputs":[{"name":"stdout","output_type":"stream","text":["30 sequence LSTM results:\n","Epoch 1, Training Loss: 1.6993088538251386\n","Epoch 2, Training Loss: 1.474142562501812\n","Epoch 3, Training Loss: 1.4137238254679803\n","Epoch 4, Training Loss: 1.3783982019963377\n","Epoch 5, Training Loss: 1.3537912187788996\n","Epoch 6, Training Loss: 1.3340486319531535\n","Epoch 7, Training Loss: 1.3190894767094876\n","Epoch 8, Training Loss: 1.3062398333403822\n","Epoch 9, Training Loss: 1.2956803129516794\n","Epoch 10, Training Loss: 1.2862978480538279\n","Epoch 11, Training Loss: 1.278085498514356\n","Epoch 12, Training Loss: 1.270350139226916\n","Epoch 13, Training Loss: 1.263484604259161\n","Epoch 14, Training Loss: 1.2579474826260537\n","Epoch 15, Training Loss: 1.252641338822969\n","Epoch 16, Training Loss: 1.2477584728480617\n","Epoch 17, Training Loss: 1.2438362084085477\n","Epoch 18, Training Loss: 1.2396418672574367\n","Epoch 19, Training Loss: 1.235707599415358\n","Epoch 20, Training Loss: 1.2322622239076741\n","Epoch 21, Training Loss: 1.2298383069188856\n","Epoch 22, Training Loss: 1.2269100274525184\n","Epoch 23, Training Loss: 1.225325421208427\n","Epoch 24, Training Loss: 1.2233063099255044\n","Epoch 25, Training Loss: 1.2213229424075975\n","Training time: 11.263746031125386 minutes\n","Accuracy of test set: 58.58575443912979%\n"]}],"source":["# Defining the LSTM model\n","class CharLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.lstm(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n","                torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharLSTM(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"30 sequence LSTM results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2a_30.pth')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7376,"status":"ok","timestamp":1710573283373,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"bmu2x5CM3Wg7"},"outputs":[],"source":["sequence_length = 50\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":777910,"status":"ok","timestamp":1710574061214,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"Uw41jw3M3Wg7","outputId":"2220c7d4-0d70-4051-9164-c87bbd6a8bab"},"outputs":[{"name":"stdout","output_type":"stream","text":["50 sequence LSTM results:\n","Epoch 1, Training Loss: 1.7033157834293955\n","Epoch 2, Training Loss: 1.472816352770021\n","Epoch 3, Training Loss: 1.4091637182092072\n","Epoch 4, Training Loss: 1.3726160892830093\n","Epoch 5, Training Loss: 1.346235753165959\n","Epoch 6, Training Loss: 1.325980530674737\n","Epoch 7, Training Loss: 1.3088446769271789\n","Epoch 8, Training Loss: 1.2956975393650298\n","Epoch 9, Training Loss: 1.284235503269634\n","Epoch 10, Training Loss: 1.2747833096490258\n","Epoch 11, Training Loss: 1.2659264016383998\n","Epoch 12, Training Loss: 1.2586697097950559\n","Epoch 13, Training Loss: 1.2507322769119893\n","Epoch 14, Training Loss: 1.245463993572946\n","Epoch 15, Training Loss: 1.240341373383272\n","Epoch 16, Training Loss: 1.234599030893411\n","Epoch 17, Training Loss: 1.2303823452566331\n","Epoch 18, Training Loss: 1.227314035949945\n","Epoch 19, Training Loss: 1.2234475778517602\n","Epoch 20, Training Loss: 1.220022144413049\n","Epoch 21, Training Loss: 1.217116185521279\n","Epoch 22, Training Loss: 1.21419994343885\n","Epoch 23, Training Loss: 1.212461400247513\n","Epoch 24, Training Loss: 1.2099621501052384\n","Epoch 25, Training Loss: 1.2077432776297752\n","Training time: 12.90316569407781 minutes\n","Accuracy of test set: 59.213965185660044%\n"]}],"source":["# Defining the LSTM model\n","class CharLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.lstm(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device),\n","                torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharLSTM(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"50 sequence LSTM results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2a_50.pth')"]},{"cell_type":"markdown","metadata":{"id":"NfFQ8Dlt3Wg8"},"source":["# **Problem 2B:** GRU(20, 30, 50)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4130,"status":"ok","timestamp":1710574065299,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"eJcOKXV-3Wg8"},"outputs":[],"source":["sequence_length = 20\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598521,"status":"ok","timestamp":1710574663742,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"Lb2Ysm953Wg9","outputId":"adf2c610-a58f-4b59-9aee-f7b00f2ab4f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["20 sequence GRU results:\n","Epoch 1, Training Loss: 1.6904839627782435\n","Epoch 2, Training Loss: 1.497342645540637\n","Epoch 3, Training Loss: 1.4507262527993952\n","Epoch 4, Training Loss: 1.4255671261270635\n","Epoch 5, Training Loss: 1.4101337558807345\n","Epoch 6, Training Loss: 1.3995701468373878\n","Epoch 7, Training Loss: 1.3912026316047195\n","Epoch 8, Training Loss: 1.3853752609391494\n","Epoch 9, Training Loss: 1.3809091519399819\n","Epoch 10, Training Loss: 1.376863594574622\n","Epoch 11, Training Loss: 1.374466078185994\n","Epoch 12, Training Loss: 1.3727443141288889\n","Epoch 13, Training Loss: 1.3720990438794378\n","Epoch 14, Training Loss: 1.3719647168873783\n","Epoch 15, Training Loss: 1.3736919506110477\n","Epoch 16, Training Loss: 1.3745446196675506\n","Epoch 17, Training Loss: 1.3749985953411423\n","Epoch 18, Training Loss: 1.3745096339723946\n","Epoch 19, Training Loss: 1.3774950651348288\n","Epoch 20, Training Loss: 1.3789241221090602\n","Epoch 21, Training Loss: 1.3827220115573393\n","Epoch 22, Training Loss: 1.3876126805342823\n","Epoch 23, Training Loss: 1.3884858456720788\n","Epoch 24, Training Loss: 1.3935831162396752\n","Epoch 25, Training Loss: 1.3947730505100557\n","Training time: 9.919338961442312 minutes\n","Accuracy of test set: 55.9645859016026%\n"]}],"source":["# Defining the GRU model\n","class CharGRU(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharGRU, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.gru(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharGRU(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"20 sequence GRU results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2b_20.pth')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4420,"status":"ok","timestamp":1710574668116,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"2vH17sM73Wg9"},"outputs":[],"source":["sequence_length = 30\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":673931,"status":"ok","timestamp":1710575341985,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"glSby-e23Wg-","outputId":"0fc2d9bd-4c76-4bd9-d5f7-3d89c9123cce"},"outputs":[{"name":"stdout","output_type":"stream","text":["30 sequence GRU results:\n","Epoch 1, Training Loss: 1.688761063437317\n","Epoch 2, Training Loss: 1.4947071062188277\n","Epoch 3, Training Loss: 1.446230951023389\n","Epoch 4, Training Loss: 1.4202568271740783\n","Epoch 5, Training Loss: 1.403517935940129\n","Epoch 6, Training Loss: 1.3898934693649043\n","Epoch 7, Training Loss: 1.3804380048538718\n","Epoch 8, Training Loss: 1.3759228813104498\n","Epoch 9, Training Loss: 1.369669947578725\n","Epoch 10, Training Loss: 1.367014287098413\n","Epoch 11, Training Loss: 1.3641738207156946\n","Epoch 12, Training Loss: 1.3612514548067791\n","Epoch 13, Training Loss: 1.3606549097300944\n","Epoch 14, Training Loss: 1.3582993330229853\n","Epoch 15, Training Loss: 1.3583210253093136\n","Epoch 16, Training Loss: 1.3583726284665345\n","Epoch 17, Training Loss: 1.3611586110060474\n","Epoch 18, Training Loss: 1.3605015400115335\n","Epoch 19, Training Loss: 1.3630748972835312\n","Epoch 20, Training Loss: 1.3640652118369347\n","Epoch 21, Training Loss: 1.3667174100756165\n","Epoch 22, Training Loss: 1.3682563400993522\n","Epoch 23, Training Loss: 1.3699411446174123\n","Epoch 24, Training Loss: 1.373385976365224\n","Epoch 25, Training Loss: 1.3744303944445313\n","Training time: 11.177410554885864 minutes\n","Accuracy of test set: 56.34747369695122%\n"]}],"source":["# Defining the GRU model\n","class CharGRU(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharGRU, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.gru(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharGRU(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"30 sequence GRU results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2b_30.pth')"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7607,"status":"ok","timestamp":1710575349545,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"f8NYquse3Wg-"},"outputs":[],"source":["sequence_length = 50\n","\n","# Create sequences and targets\n","sequences = []\n","targets = []\n","for i in range(0, len(encoded_text) - sequence_length):\n","    seq = encoded_text[i:i+sequence_length]\n","    target = encoded_text[i+sequence_length]\n","    sequences.append(seq)\n","    targets.append(target)\n","\n","# Convert lists to PyTorch tensors\n","sequences = torch.tensor(sequences, dtype=torch.long)\n","targets = torch.tensor(targets, dtype=torch.long)\n","\n","# Dataset class\n","class CharDataset(Dataset):\n","    def __init__(self, sequences, targets):\n","        self.sequences = sequences\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.sequences)\n","\n","    def __getitem__(self, index):\n","        return self.sequences[index], self.targets[index]\n","\n","# Instantiate the dataset\n","dataset = CharDataset(sequences, targets)\n","\n","# Create data loaders\n","batch_size = 128\n","train_size = int(len(dataset) * 0.8)\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":772394,"status":"ok","timestamp":1710576121880,"user":{"displayName":"Patrick Ballou","userId":"16585721253779447514"},"user_tz":240},"id":"9bHfM5n03Wg_","outputId":"a4ffc66c-fbe3-4cee-94e3-7aa5b84e5b01"},"outputs":[{"name":"stdout","output_type":"stream","text":["50 sequence GRU results:\n","Epoch 1, Training Loss: 1.6804511425160316\n","Epoch 2, Training Loss: 1.4817302748678474\n","Epoch 3, Training Loss: 1.435106966865232\n","Epoch 4, Training Loss: 1.4087642558830709\n","Epoch 5, Training Loss: 1.3914834176548379\n","Epoch 6, Training Loss: 1.3802862838049597\n","Epoch 7, Training Loss: 1.3710225728881391\n","Epoch 8, Training Loss: 1.3649185802036712\n","Epoch 9, Training Loss: 1.3613395527092838\n","Epoch 10, Training Loss: 1.356445742951389\n","Epoch 11, Training Loss: 1.353771461371352\n","Epoch 12, Training Loss: 1.353007037043486\n","Epoch 13, Training Loss: 1.3511901474925885\n","Epoch 14, Training Loss: 1.3503325411740206\n","Epoch 15, Training Loss: 1.349965271555083\n","Epoch 16, Training Loss: 1.3516816538403869\n","Epoch 17, Training Loss: 1.351813011686902\n","Epoch 18, Training Loss: 1.3515537315419819\n","Epoch 19, Training Loss: 1.3527359983668301\n","Epoch 20, Training Loss: 1.3570245269842562\n","Epoch 21, Training Loss: 1.3570453758784233\n","Epoch 22, Training Loss: 1.3602206598924027\n","Epoch 23, Training Loss: 1.3637807675848526\n","Epoch 24, Training Loss: 1.365017493560177\n","Epoch 25, Training Loss: 1.368766647631153\n","Training time: 12.810324263572692 minutes\n","Accuracy of test set: 56.79632759370419%\n"]}],"source":["# Defining the GRU model\n","class CharGRU(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(CharGRU, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden):\n","        embedded = self.embedding(x)\n","        output, hidden = self.gru(embedded, hidden)\n","        output = self.fc(output[:, -1, :])\n","        return output, hidden\n","\n","    def init_hidden(self, batch_size):\n","        return (torch.zeros(1, batch_size, self.hidden_size, device=device))\n","\n","# Hyperparameters\n","input_size = len(chars)\n","hidden_size = 256\n","output_size = len(chars)\n","learning_rate = 0.001\n","\n","# Model, loss, and optimizer\n","model = CharGRU(input_size, hidden_size, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epochs = 25\n","\n","init_time = time.time()\n","print(\"50 sequence GRU results:\")\n","\n","# Training the model\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {running_loss / len(train_loader)}\")\n","\n","print(f\"Training time: {(time.time() - init_time)/60} minutes\")\n","\n","# Validation\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        hidden = model.init_hidden(data.size(0))\n","        output, hidden = model(data, hidden)\n","        _, predicted = torch.max(output.data, 1)\n","        total += target.size(0)\n","        correct += (predicted == target).sum().item()\n","\n","print(f\"Accuracy of test set: {100 * correct / total}%\")\n","\n","#torch.save(model.state_dict(), '../../Models/hw3_2b_50.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
