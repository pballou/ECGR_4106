{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPatrick Ballou\\nID: 801130521\\nECGR 4106\\nHomework 4\\nProblem 3\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Patrick Ballou\n",
    "ID: 801130521\n",
    "ECGR 4106\n",
    "Homework 4\n",
    "Problem 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  Quadro T2000\n",
      "Mon Apr 15 14:04:41 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro T2000                 WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8              6W /   60W |    1915MiB /   4096MiB |      9%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2084    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A      3148    C+G   ...e Stream\\89.0.2.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A      6212    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     10052    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A     10604    C+G   ....1300.0_x64__8j3eq9eme6ctt\\IGCC.exe      N/A      |\n",
      "|    0   N/A  N/A     12068    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     13612    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     14436    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15644    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16524    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A     17168    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     18440    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19164    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19280    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A     20356    C+G   ...91.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n",
      "|    0   N/A  N/A     21180    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     21636    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     24908      C   ...ri\\anaconda3\\envs\\dl_env\\python.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#check if GPU is available and set the device accordingly\n",
    "#device = 'torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")'\n",
    "device = 'cuda'\n",
    "print(\"Using GPU: \", cuda.get_device_name())\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    (\"J'ai froid\", \"I am cold\"),\n",
    "    (\"Tu es fatigué\", \"You are tired\"),\n",
    "    (\"Il a faim\", \"He is hungry\"),\n",
    "    (\"Elle est heureuse\", \"She is happy\"),\n",
    "    (\"Nous sommes amis\", \"We are friends\"),\n",
    "    (\"Ils sont étudiants\", \"They are students\"),\n",
    "    (\"Le chat dort\", \"The cat is sleeping\"),\n",
    "    (\"Le soleil brille\", \"The sun is shining\"),\n",
    "    (\"Nous aimons la musique\", \"We love music\"),\n",
    "    (\"Elle parle français couramment\", \"She speaks French fluently\"),\n",
    "    (\"Il aime lire des livres\", \"He enjoys reading books\"),\n",
    "    (\"Ils jouent au football chaque week-end\", \"They play soccer every weekend\"),\n",
    "    (\"Le film commence à 19 heures\", \"The movie starts at 7 PM\"),\n",
    "    (\"Elle porte une robe rouge\", \"She wears a red dress\"),\n",
    "    (\"Nous cuisinons le dîner ensemble\", \"We cook dinner together\"),\n",
    "    (\"Il conduit une voiture bleue\", \"He drives a blue car\"),\n",
    "    (\"Ils visitent souvent des musées\", \"They visit museums often\"),\n",
    "    (\"Le restaurant sert une délicieuse cuisine\", \"The restaurant serves delicious food\"),\n",
    "    (\"Elle étudie les mathématiques à l'université\", \"She studies mathematics at university\"),\n",
    "    (\"Nous regardons des films le vendredi\", \"We watch movies on Fridays\"),\n",
    "    (\"Il écoute de la musique en faisant du jogging\", \"He listens to music while jogging\"),\n",
    "    (\"Ils voyagent autour du monde\", \"They travel around the world\"),\n",
    "    (\"Le livre est sur la table\", \"The book is on the table\"),\n",
    "    (\"Elle danse avec grâce\", \"She dances gracefully\"),\n",
    "    (\"Nous célébrons les anniversaires avec un gâteau\", \"We celebrate birthdays with cake\"),\n",
    "    (\"Il travaille dur tous les jours\", \"He works hard every day\"),\n",
    "    (\"Ils parlent différentes langues\", \"They speak different languages\"),\n",
    "    (\"Les fleurs fleurissent au printemps\", \"The flowers bloom in spring\"),\n",
    "    (\"Elle écrit de la poésie pendant son temps libre\", \"She writes poetry in her free time\"),\n",
    "    (\"Nous apprenons quelque chose de nouveau chaque jour\", \"We learn something new every day\"),\n",
    "    (\"Le chien aboie bruyamment\", \"The dog barks loudly\"),\n",
    "    (\"Il chante magnifiquement\", \"He sings beautifully\"),\n",
    "    (\"Ils nagent dans la piscine\", \"They swim in the pool\"),\n",
    "    (\"Les oiseaux gazouillent le matin\", \"The birds chirp in the morning\"),\n",
    "    (\"Elle enseigne l'anglais à l'école\", \"She teaches English at school\"),\n",
    "    (\"Nous prenons le petit déjeuner ensemble\", \"We eat breakfast together\"),\n",
    "    (\"Il peint des paysages\", \"He paints landscapes\"),\n",
    "    (\"Ils rient de la blague\", \"They laugh at the joke\"),\n",
    "    (\"L'horloge tic-tac bruyamment\", \"The clock ticks loudly\"),\n",
    "    (\"Elle court dans le parc\", \"She runs in the park\"),\n",
    "    (\"Nous voyageons en train\", \"We travel by train\"),\n",
    "    (\"Il écrit une lettre\", \"He writes a letter\"),\n",
    "    (\"Ils lisent des livres à la bibliothèque\", \"They read books at the library\"),\n",
    "    (\"Le bébé pleure\", \"The baby cries\"),\n",
    "    (\"Elle étudie dur pour les examens\", \"She studies hard for exams\"),\n",
    "    (\"Nous plantons des fleurs dans le jardin\", \"We plant flowers in the garden\"),\n",
    "    (\"Il répare la voiture\", \"He fixes the car\"),\n",
    "    (\"Ils boivent du café le matin\", \"They drink coffee in the morning\"),\n",
    "    (\"Le soleil se couche le soir\", \"The sun sets in the evening\"),\n",
    "    (\"Elle danse à la fête\", \"She dances at the party\"),\n",
    "    (\"Nous jouons de la musique au concert\", \"We play music at the concert\"),\n",
    "    (\"Il cuisine le dîner pour sa famille\", \"He cooks dinner for his family\"),\n",
    "    (\"Ils étudient la grammaire française\", \"They study French grammar\"),\n",
    "    (\"La pluie tombe doucement\", \"The rain falls gently\"),\n",
    "    (\"Elle chante une chanson\", \"She sings a song\"),\n",
    "    (\"Nous regardons un film ensemble\", \"We watch a movie together\"),\n",
    "    (\"Il dort profondément\", \"He sleeps deeply\"),\n",
    "    (\"Ils voyagent à Paris\", \"They travel to Paris\"),\n",
    "    (\"Les enfants jouent dans le parc\", \"The children play in the park\"),\n",
    "    (\"Elle se promène le long de la plage\", \"She walks along the beach\"),\n",
    "    (\"Nous parlons au téléphone\", \"We talk on the phone\"),\n",
    "    (\"Il attend le bus\", \"He waits for the bus\"),\n",
    "    (\"Ils visitent la tour Eiffel\", \"They visit the Eiffel Tower\"),\n",
    "    (\"Les étoiles scintillent la nuit\", \"The stars twinkle at night\"),\n",
    "    (\"Elle rêve de voler\", \"She dreams of flying\"),\n",
    "    (\"Nous travaillons au bureau\", \"We work in the office\"),\n",
    "    (\"Il étudie l'histoire\", \"He studies history\"),\n",
    "    (\"Ils écoutent la radio\", \"They listen to the radio\"),\n",
    "    (\"Le vent souffle doucement\", \"The wind blows gently\"),\n",
    "    (\"Elle nage dans l'océan\", \"She swims in the ocean\"),\n",
    "    (\"Nous dansons au mariage\", \"We dance at the wedding\"),\n",
    "    (\"Il gravit la montagne\", \"He climbs the mountain\"),\n",
    "    (\"Ils font de la randonnée dans la forêt\", \"They hike in the forest\"),\n",
    "    (\"Le chat miaule bruyamment\", \"The cat meows loudly\"),\n",
    "    (\"Elle peint un tableau\", \"She paints a picture\"),\n",
    "    (\"Nous construisons un château de sable\", \"We build a sandcastle\"),\n",
    "    (\"Il chante dans le chœur\", \"He sings in the choir\")\n",
    "]\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem 3A:** French to English without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary class to handle mapping between words and numerical indices\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Initialize dictionaries for word to index and index to word mappings\n",
    "        self.word2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n",
    "        self.index2word = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n",
    "        self.word_count = {}  # Keep track of word frequencies\n",
    "        self.n_words = 2  # Start counting from 2 to account for special tokens\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        # Add all words in a sentence to the vocabulary\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        # Add a word to the vocabulary\n",
    "        if word not in self.word2index:\n",
    "            # Assign a new index to the word and update mappings\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # Increment word count if the word already exists in the vocabulary\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "# Custom Dataset class for English to French sentences\n",
    "class EngFrDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.eng_vocab = Vocabulary()\n",
    "        self.fr_vocab = Vocabulary()\n",
    "        self.pairs = []\n",
    "\n",
    "        # Process each English-French pair\n",
    "        for eng, fr in pairs:\n",
    "            self.eng_vocab.add_sentence(eng)\n",
    "            self.fr_vocab.add_sentence(fr)\n",
    "            self.pairs.append((eng, fr))\n",
    "\n",
    "        # Separate English and French sentences\n",
    "        self.eng_sentences = [pair[0] for pair in self.pairs]\n",
    "        self.fr_sentences = [pair[1] for pair in self.pairs]\n",
    "    \n",
    "    # Returns the number of pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    # Get the sentences by index\n",
    "    def __getitem__(self, idx):\n",
    "        input_sentence = self.eng_sentences[idx]\n",
    "        target_sentence = self.fr_sentences[idx]\n",
    "        input_indices = [self.eng_vocab.word2index[word] for word in input_sentence.split()] + [EOS_token]\n",
    "        target_indices = [self.fr_vocab.word2index[word] for word in target_sentence.split()] + [EOS_token]\n",
    "        \n",
    "        return torch.tensor(input_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
    "\n",
    "# Initialize the dataset and DataLoader\n",
    "e2f_dataset = EngFrDataset(text)\n",
    "dataloader = DataLoader(e2f_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"The Encoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # Embedding layer\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)  # GRU layer\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The Decoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoding each character in the input\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "    # Decoder's first input is the SOS token\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    # Decoder starts with encoder's last hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Decoding loop\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top1 word from decoder's output\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Detach from history as input\n",
    "\n",
    "        # Calculate loss\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update encoder and decoder\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # Return average loss\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_tensor, target_tensor in dataloader:\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "            \n",
    "            # Perform a single training step and update loss\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            total_loss += loss\n",
    "        \n",
    "        # Print loss every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples=10):\n",
    "    # Switch model to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "            # Move tensors to the correct device\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "\n",
    "            input_length = input_tensor.size(0)\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            # Encoding step\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "            # Decoding step\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = []\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                predicted_indices.append(topi.item())\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "            # Calculate and print loss and accuracy for the evaluation\n",
    "            total_loss += loss.item() / target_length\n",
    "            if predicted_indices == target_tensor.tolist():\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Print some examples\n",
    "            if i < n_examples:\n",
    "                predicted_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index] for index in predicted_indices if index not in (SOS_token, EOS_token)])\n",
    "                target_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index.item()] for index in target_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "                input_sentence = ' '.join([dataloader.dataset.eng_vocab.index2word[index.item()] for index in input_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "\n",
    "                print(f'Input: {input_sentence}, Target: {target_sentence}, Predicted: {predicted_sentence}')\n",
    "\n",
    "        # Print overall evaluation results\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / len(dataloader)\n",
    "        print(f'Evaluation Loss: {average_loss:.4f}, Accuracy: {100*accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "epochs = 51\n",
    "learning_rate = 0.01\n",
    "hidden_size = 1028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.0847776353690977\n",
      "Epoch 5, Loss: 2.391458537877896\n",
      "Epoch 10, Loss: 1.2405039028171851\n",
      "Epoch 15, Loss: 0.20794280146697305\n",
      "Epoch 20, Loss: 0.05064842285716246\n",
      "Epoch 25, Loss: 0.03017518640154293\n",
      "Epoch 30, Loss: 0.021479093558837505\n",
      "Epoch 35, Loss: 0.016620042057098543\n",
      "Epoch 40, Loss: 0.01352441101706481\n",
      "Epoch 45, Loss: 0.011378455714851927\n",
      "Epoch 50, Loss: 0.009802569154806633\n"
     ]
    }
   ],
   "source": [
    "input_size = len(e2f_dataset.eng_vocab.word2index)\n",
    "output_size = len(e2f_dataset.fr_vocab.word2index)\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Nous travaillons au bureau, Target: We work in the office, Predicted: We work in the office\n",
      "Input: Le soleil brille, Target: The sun is shining, Predicted: The sun is shining\n",
      "Input: Il peint des paysages, Target: He paints landscapes, Predicted: He paints landscapes\n",
      "Input: Nous jouons de la musique au concert, Target: We play music at the concert, Predicted: We play music at the concert\n",
      "Input: Nous parlons au téléphone, Target: We talk on the phone, Predicted: We talk on the phone\n",
      "Input: Elle écrit de la poésie pendant son temps libre, Target: She writes poetry in her free time, Predicted: She writes poetry in her free time\n",
      "Input: Il répare la voiture, Target: He fixes the car, Predicted: He fixes the car\n",
      "Input: Nous regardons des films le vendredi, Target: We watch movies on Fridays, Predicted: We watch movies on Fridays\n",
      "Input: Il attend le bus, Target: He waits for the bus, Predicted: He waits for the bus\n",
      "Input: Elle se promène le long de la plage, Target: She walks along the beach, Predicted: She walks along the beach\n",
      "Evaluation Loss: 0.0094, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_examples(encoder, decoder, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), '../../Models/hw4_3a_encoder.pth')\n",
    "torch.save(decoder.state_dict(), '../../Models/hw4_3b_decoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Problem 3B:** French to English with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder with attention\n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, max_length=16, dropout_p=0.1):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size) # Embedding layer\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length) # Attention layer\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) # Combining layer\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        # Calculating attention weights\n",
    "        attn_weights = torch.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        # Combining embedded input with attention output\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = torch.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = torch.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=16):\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoding each character in the input\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # Decoder's first input is the SOS token\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    # Decoder starts with encoder's last hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "   # Decoding loop with attention\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Detach from history as input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update encoder and decoder\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # Return average loss\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_tensor, target_tensor in dataloader:\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "            \n",
    "            # Perform a single training step and update loss\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            total_loss += loss\n",
    "        \n",
    "        # Print loss every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples=10, max_length=16):\n",
    "    # Switch model to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "            # Move tensors to the correct device\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "\n",
    "            input_length = input_tensor.size(0)\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            # Encoding each character in the input\n",
    "            encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "                encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "            # Decoding step\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = []\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                predicted_indices.append(topi.item())\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "            # Calculate and print loss and accuracy for the evaluation\n",
    "            total_loss += loss.item() / target_length\n",
    "            if predicted_indices == target_tensor.tolist():\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Print some examples\n",
    "            if i < n_examples:\n",
    "                predicted_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index] for index in predicted_indices if index not in (SOS_token, EOS_token)])\n",
    "                target_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index.item()] for index in target_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "                input_sentence = ' '.join([dataloader.dataset.eng_vocab.index2word[index.item()] for index in input_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "\n",
    "                print(f'Input: {input_sentence}, Target: {target_sentence}, Predicted: {predicted_sentence}')\n",
    "\n",
    "        # Print overall evaluation results\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / len(dataloader)\n",
    "        print(f'Evaluation Loss: {average_loss:.4f}, Accuracy: {100*accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "epochs = 51\n",
    "learning_rate = 0.01\n",
    "hidden_size = 1028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.0278098774310176\n",
      "Epoch 5, Loss: 2.410202463983974\n",
      "Epoch 10, Loss: 1.2605623107820512\n",
      "Epoch 15, Loss: 0.30540076114960707\n",
      "Epoch 20, Loss: 0.06631536839498772\n",
      "Epoch 25, Loss: 0.033590564190945145\n",
      "Epoch 30, Loss: 0.021999660827998185\n",
      "Epoch 35, Loss: 0.01609092903627002\n",
      "Epoch 40, Loss: 0.012645105581302092\n",
      "Epoch 45, Loss: 0.01031990974096739\n",
      "Epoch 50, Loss: 0.008761231182459866\n"
     ]
    }
   ],
   "source": [
    "input_size = len(e2f_dataset.eng_vocab.word2index)\n",
    "output_size = len(e2f_dataset.fr_vocab.word2index)\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = AttentionDecoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Ils voyagent à Paris, Target: They travel to Paris, Predicted: They travel to Paris\n",
      "Input: Nous aimons la musique, Target: We love music, Predicted: We love music\n",
      "Input: Tu es fatigué, Target: You are tired, Predicted: You are tired\n",
      "Input: Il cuisine le dîner pour sa famille, Target: He cooks dinner for his family, Predicted: He cooks dinner for his family\n",
      "Input: Il conduit une voiture bleue, Target: He drives a blue car, Predicted: He drives a blue car\n",
      "Input: Il chante magnifiquement, Target: He sings beautifully, Predicted: He sings beautifully\n",
      "Input: Nous jouons de la musique au concert, Target: We play music at the concert, Predicted: We play music at the concert\n",
      "Input: Ils boivent du café le matin, Target: They drink coffee in the morning, Predicted: They drink coffee in the morning\n",
      "Input: Le chat miaule bruyamment, Target: The cat meows loudly, Predicted: The cat meows loudly\n",
      "Input: Il aime lire des livres, Target: He enjoys reading books, Predicted: He enjoys reading books\n",
      "Evaluation Loss: 0.0082, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_examples(encoder, decoder, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), '../../Models/hw4_3b_encoder.pth')\n",
    "torch.save(decoder.state_dict(), '../../Models/hw4_3b_decoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
