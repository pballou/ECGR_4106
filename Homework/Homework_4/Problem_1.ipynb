{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPatrick Ballou\\nID: 801130521\\nECGR 4106\\nHomework 4\\nProblem 1\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Patrick Ballou\n",
    "ID: 801130521\n",
    "ECGR 4106\n",
    "Homework 4\n",
    "Problem 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU:  Quadro T2000\n",
      "Mon Apr 15 11:57:51 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.86                 Driver Version: 551.86         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Quadro T2000                 WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   46C    P5              8W /   30W |    1561MiB /   4096MiB |     14%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1176      C   ...ri\\anaconda3\\envs\\dl_env\\python.exe      N/A      |\n",
      "|    0   N/A  N/A      2084    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A      3148    C+G   ...e Stream\\89.0.2.0\\GoogleDriveFS.exe      N/A      |\n",
      "|    0   N/A  N/A      6212    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     10052    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "|    0   N/A  N/A     10604    C+G   ....1300.0_x64__8j3eq9eme6ctt\\IGCC.exe      N/A      |\n",
      "|    0   N/A  N/A     12068    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     14436    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15644    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16524    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A     17168    C+G   ...aam7r\\AcrobatNotificationClient.exe      N/A      |\n",
      "|    0   N/A  N/A     18440    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19164    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     19280    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A     19304    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     20356    C+G   ...91.0_x64__8wekyb3d8bbwe\\GameBar.exe      N/A      |\n",
      "|    0   N/A  N/A     21180    C+G   ...AppData\\Roaming\\Spotify\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     21636    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#check if GPU is available and set the device accordingly\n",
    "#device = 'torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")'\n",
    "device = 'cuda'\n",
    "print(\"Using GPU: \", cuda.get_device_name())\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    (\"I am cold\", \"J'ai froid\"),\n",
    "    (\"You are tired\", \"Tu es fatigué\"),\n",
    "    (\"He is hungry\", \"Il a faim\"),\n",
    "    (\"She is happy\", \"Elle est heureuse\"),\n",
    "    (\"We are friends\", \"Nous sommes amis\"),\n",
    "    (\"They are students\", \"Ils sont étudiants\"),\n",
    "    (\"The cat is sleeping\", \"Le chat dort\"),\n",
    "    (\"The sun is shining\", \"Le soleil brille\"),\n",
    "    (\"We love music\", \"Nous aimons la musique\"),\n",
    "    (\"She speaks French fluently\", \"Elle parle français couramment\"),\n",
    "    (\"He enjoys reading books\", \"Il aime lire des livres\"),\n",
    "    (\"They play soccer every weekend\", \"Ils jouent au football chaque week-end\"),\n",
    "    (\"The movie starts at 7 PM\", \"Le film commence à 19 heures\"),\n",
    "    (\"She wears a red dress\", \"Elle porte une robe rouge\"),\n",
    "    (\"We cook dinner together\", \"Nous cuisinons le dîner ensemble\"),\n",
    "    (\"He drives a blue car\", \"Il conduit une voiture bleue\"),\n",
    "    (\"They visit museums often\", \"Ils visitent souvent des musées\"),\n",
    "    (\"The restaurant serves delicious food\", \"Le restaurant sert une délicieuse cuisine\"),\n",
    "    (\"She studies mathematics at university\", \"Elle étudie les mathématiques à l'université\"),\n",
    "    (\"We watch movies on Fridays\", \"Nous regardons des films le vendredi\"),\n",
    "    (\"He listens to music while jogging\", \"Il écoute de la musique en faisant du jogging\"),\n",
    "    (\"They travel around the world\", \"Ils voyagent autour du monde\"),\n",
    "    (\"The book is on the table\", \"Le livre est sur la table\"),\n",
    "    (\"She dances gracefully\", \"Elle danse avec grâce\"),\n",
    "    (\"We celebrate birthdays with cake\", \"Nous célébrons les anniversaires avec un gâteau\"),\n",
    "    (\"He works hard every day\", \"Il travaille dur tous les jours\"),\n",
    "    (\"They speak different languages\", \"Ils parlent différentes langues\"),\n",
    "    (\"The flowers bloom in spring\", \"Les fleurs fleurissent au printemps\"),\n",
    "    (\"She writes poetry in her free time\", \"Elle écrit de la poésie pendant son temps libre\"),\n",
    "    (\"We learn something new every day\", \"Nous apprenons quelque chose de nouveau chaque jour\"),\n",
    "    (\"The dog barks loudly\", \"Le chien aboie bruyamment\"),\n",
    "    (\"He sings beautifully\", \"Il chante magnifiquement\"),\n",
    "    (\"They swim in the pool\", \"Ils nagent dans la piscine\"),\n",
    "    (\"The birds chirp in the morning\", \"Les oiseaux gazouillent le matin\"),\n",
    "    (\"She teaches English at school\", \"Elle enseigne l'anglais à l'école\"),\n",
    "    (\"We eat breakfast together\", \"Nous prenons le petit déjeuner ensemble\"),\n",
    "    (\"He paints landscapes\", \"Il peint des paysages\"),\n",
    "    (\"They laugh at the joke\", \"Ils rient de la blague\"),\n",
    "    (\"The clock ticks loudly\", \"L'horloge tic-tac bruyamment\"),\n",
    "    (\"She runs in the park\", \"Elle court dans le parc\"),\n",
    "    (\"We travel by train\", \"Nous voyageons en train\"),\n",
    "    (\"He writes a letter\", \"Il écrit une lettre\"),\n",
    "    (\"They read books at the library\", \"Ils lisent des livres à la bibliothèque\"),\n",
    "    (\"The baby cries\", \"Le bébé pleure\"),\n",
    "    (\"She studies hard for exams\", \"Elle étudie dur pour les examens\"),\n",
    "    (\"We plant flowers in the garden\", \"Nous plantons des fleurs dans le jardin\"),\n",
    "    (\"He fixes the car\", \"Il répare la voiture\"),\n",
    "    (\"They drink coffee in the morning\", \"Ils boivent du café le matin\"),\n",
    "    (\"The sun sets in the evening\", \"Le soleil se couche le soir\"),\n",
    "    (\"She dances at the party\", \"Elle danse à la fête\"),\n",
    "    (\"We play music at the concert\", \"Nous jouons de la musique au concert\"),\n",
    "    (\"He cooks dinner for his family\", \"Il cuisine le dîner pour sa famille\"),\n",
    "    (\"They study French grammar\", \"Ils étudient la grammaire française\"),\n",
    "    (\"The rain falls gently\", \"La pluie tombe doucement\"),\n",
    "    (\"She sings a song\", \"Elle chante une chanson\"),\n",
    "    (\"We watch a movie together\", \"Nous regardons un film ensemble\"),\n",
    "    (\"He sleeps deeply\", \"Il dort profondément\"),\n",
    "    (\"They travel to Paris\", \"Ils voyagent à Paris\"),\n",
    "    (\"The children play in the park\", \"Les enfants jouent dans le parc\"),\n",
    "    (\"She walks along the beach\", \"Elle se promène le long de la plage\"),\n",
    "    (\"We talk on the phone\", \"Nous parlons au téléphone\"),\n",
    "    (\"He waits for the bus\", \"Il attend le bus\"),\n",
    "    (\"They visit the Eiffel Tower\", \"Ils visitent la tour Eiffel\"),\n",
    "    (\"The stars twinkle at night\", \"Les étoiles scintillent la nuit\"),\n",
    "    (\"She dreams of flying\", \"Elle rêve de voler\"),\n",
    "    (\"We work in the office\", \"Nous travaillons au bureau\"),\n",
    "    (\"He studies history\", \"Il étudie l'histoire\"),\n",
    "    (\"They listen to the radio\", \"Ils écoutent la radio\"),\n",
    "    (\"The wind blows gently\", \"Le vent souffle doucement\"),\n",
    "    (\"She swims in the ocean\", \"Elle nage dans l'océan\"),\n",
    "    (\"We dance at the wedding\", \"Nous dansons au mariage\"),\n",
    "    (\"He climbs the mountain\", \"Il gravit la montagne\"),\n",
    "    (\"They hike in the forest\", \"Ils font de la randonnée dans la forêt\"),\n",
    "    (\"The cat meows loudly\", \"Le chat miaule bruyamment\"),\n",
    "    (\"She paints a picture\", \"Elle peint un tableau\"),\n",
    "    (\"We build a sandcastle\", \"Nous construisons un château de sable\"),\n",
    "    (\"He sings in the choir\", \"Il chante dans le chœur\")\n",
    "]\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary class to handle mapping between words and numerical indices\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Initialize dictionaries for word to index and index to word mappings\n",
    "        self.word2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token}\n",
    "        self.index2word = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\"}\n",
    "        self.word_count = {}  # Keep track of word frequencies\n",
    "        self.n_words = 2  # Start counting from 2 to account for special tokens\n",
    "        \n",
    "    def add_sentence(self, sentence):\n",
    "        # Add all words in a sentence to the vocabulary\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "            \n",
    "    def add_word(self, word):\n",
    "        # Add a word to the vocabulary\n",
    "        if word not in self.word2index:\n",
    "            # Assign a new index to the word and update mappings\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word_count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            # Increment word count if the word already exists in the vocabulary\n",
    "            self.word_count[word] += 1\n",
    "\n",
    "# Custom Dataset class for English to French sentences\n",
    "class EngFrDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.eng_vocab = Vocabulary()\n",
    "        self.fr_vocab = Vocabulary()\n",
    "        self.pairs = []\n",
    "\n",
    "        # Process each English-French pair\n",
    "        for eng, fr in pairs:\n",
    "            self.eng_vocab.add_sentence(eng)\n",
    "            self.fr_vocab.add_sentence(fr)\n",
    "            self.pairs.append((eng, fr))\n",
    "\n",
    "        # Separate English and French sentences\n",
    "        self.eng_sentences = [pair[0] for pair in self.pairs]\n",
    "        self.fr_sentences = [pair[1] for pair in self.pairs]\n",
    "    \n",
    "    # Returns the number of pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    # Get the sentences by index\n",
    "    def __getitem__(self, idx):\n",
    "        input_sentence = self.eng_sentences[idx]\n",
    "        target_sentence = self.fr_sentences[idx]\n",
    "        input_indices = [self.eng_vocab.word2index[word] for word in input_sentence.split()] + [EOS_token]\n",
    "        target_indices = [self.fr_vocab.word2index[word] for word in target_sentence.split()] + [EOS_token]\n",
    "        \n",
    "        return torch.tensor(input_indices, dtype=torch.long), torch.tensor(target_indices, dtype=torch.long)\n",
    "\n",
    "# Initialize the dataset and DataLoader\n",
    "e2f_dataset = EngFrDataset(text)\n",
    "dataloader = DataLoader(e2f_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"The Encoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)  # Embedding layer\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)  # GRU layer\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"The Decoder part of the seq2seq model.\"\"\"\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    # Initialize encoder hidden state\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    # Encoding each character in the input\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "    # Decoder's first input is the SOS token\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    # Decoder starts with encoder's last hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # Decoding loop\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        # Choose top1 word from decoder's output\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # Detach from history as input\n",
    "\n",
    "        # Calculate loss\n",
    "        loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update encoder and decoder\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    # Return average loss\n",
    "    return loss.item() / target_length\n",
    "\n",
    "def train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for input_tensor, target_tensor in dataloader:\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "            \n",
    "            # Perform a single training step and update loss\n",
    "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            total_loss += loss\n",
    "        \n",
    "        # Print loss every 5 epochs\n",
    "        if epoch % 5 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_show_examples(encoder, decoder, dataloader, criterion, n_examples=10):\n",
    "    # Switch model to evaluation mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for i, (input_tensor, target_tensor) in enumerate(dataloader):\n",
    "            # Move tensors to the correct device\n",
    "            input_tensor = input_tensor[0].to(device)\n",
    "            target_tensor = target_tensor[0].to(device)\n",
    "\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "\n",
    "            input_length = input_tensor.size(0)\n",
    "            target_length = target_tensor.size(0)\n",
    "\n",
    "            loss = 0\n",
    "\n",
    "            # Encoding step\n",
    "            for ei in range(input_length):\n",
    "                encoder_output, encoder_hidden = encoder(input_tensor[ei].unsqueeze(0), encoder_hidden)\n",
    "\n",
    "            # Decoding step\n",
    "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            predicted_indices = []\n",
    "\n",
    "            for di in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                predicted_indices.append(topi.item())\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "                loss += criterion(decoder_output, target_tensor[di].unsqueeze(0))\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "\n",
    "            # Calculate and print loss and accuracy for the evaluation\n",
    "            total_loss += loss.item() / target_length\n",
    "            if predicted_indices == target_tensor.tolist():\n",
    "                correct_predictions += 1\n",
    "\n",
    "            # Print some examples\n",
    "            if i < n_examples:\n",
    "                predicted_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index] for index in predicted_indices if index not in (SOS_token, EOS_token)])\n",
    "                target_sentence = ' '.join([dataloader.dataset.fr_vocab.index2word[index.item()] for index in target_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "                input_sentence = ' '.join([dataloader.dataset.eng_vocab.index2word[index.item()] for index in input_tensor if index.item() not in (SOS_token, EOS_token)])\n",
    "\n",
    "                print(f'Input: {input_sentence}, Target: {target_sentence}, Predicted: {predicted_sentence}')\n",
    "\n",
    "        # Print overall evaluation results\n",
    "        average_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct_predictions / len(dataloader)\n",
    "        print(f'Evaluation Loss: {average_loss:.4f}, Accuracy: {100*accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "epochs = 51\n",
    "learning_rate = 0.01\n",
    "hidden_size = 1028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.479523268251708\n",
      "Epoch 5, Loss: 2.4761671150917617\n",
      "Epoch 10, Loss: 1.34410981452728\n",
      "Epoch 15, Loss: 0.4029710673511494\n",
      "Epoch 20, Loss: 0.111238581571099\n",
      "Epoch 25, Loss: 0.03839110464373709\n",
      "Epoch 30, Loss: 0.02439764090154225\n",
      "Epoch 35, Loss: 0.018448227389585636\n",
      "Epoch 40, Loss: 0.014817427380048499\n",
      "Epoch 45, Loss: 0.0123648420987615\n",
      "Epoch 50, Loss: 0.010606209402207006\n"
     ]
    }
   ],
   "source": [
    "input_size = len(e2f_dataset.eng_vocab.word2index)\n",
    "output_size = len(e2f_dataset.fr_vocab.word2index)\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "train__loop(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, dataloader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: We love music, Target: Nous aimons la musique, Predicted: Nous aimons la musique\n",
      "Input: She dances at the party, Target: Elle danse à la fête, Predicted: Elle danse à la fête\n",
      "Input: The movie starts at 7 PM, Target: Le film commence à 19 heures, Predicted: Le film commence à 19 heures\n",
      "Input: We plant flowers in the garden, Target: Nous plantons des fleurs dans le jardin, Predicted: Nous plantons des fleurs dans le jardin\n",
      "Input: He studies history, Target: Il étudie l'histoire, Predicted: Il étudie l'histoire\n",
      "Input: She dreams of flying, Target: Elle rêve de voler, Predicted: Elle rêve de voler\n",
      "Input: She teaches English at school, Target: Elle enseigne l'anglais à l'école, Predicted: Elle enseigne l'anglais à l'école\n",
      "Input: We learn something new every day, Target: Nous apprenons quelque chose de nouveau chaque jour, Predicted: Nous apprenons quelque chose de nouveau chaque jour\n",
      "Input: She paints a picture, Target: Elle peint un tableau, Predicted: Elle peint un tableau\n",
      "Input: We cook dinner together, Target: Nous cuisinons le dîner ensemble, Predicted: Nous cuisinons le dîner ensemble\n",
      "Evaluation Loss: 0.0102, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate_and_show_examples(encoder, decoder, dataloader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), '../../Models/hw4_1_encoder.pth')\n",
    "torch.save(decoder.state_dict(), '../../Models/hw4_1_decoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
